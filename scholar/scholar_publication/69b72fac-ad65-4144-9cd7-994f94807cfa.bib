@article{bielak2021graph,
 abstract = {The self-supervised learning (SSL) paradigm is an essential exploration area, which tries to eliminate the need for expensive data labeling. Despite the great success of SSL methods in computer vision and natural language processing, most of them employ contrastive learning objectives that require negative samples, which are hard to define. This becomes even more challenging in the case of graphs and is a bottleneck for achieving robust representations. To overcome such limitations, we propose a framework for self-supervised graph},
 author = {Bielak, Piotr and Kajdanowicz, Tomasz and Chawla, Nitesh V},
 journal = {arXiv preprint arXiv:2106.02466},
 pub_year = {2021},
 title = {Graph Barlow Twins: A self-supervised representation learning framework for graphs},
 venue = {arXiv preprint arXiv:2106.02466}
}

